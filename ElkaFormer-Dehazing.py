# -*- coding: utf-8 -*-
"""elkaformer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YaYtK2VPVS3wwIMkQDjDRyz1nLjHNKdC
"""

# ============================================================================
# OPTIMIZED ELKAformer Dehazing - High Quality Output
# ============================================================================

from google.colab import drive
drive.mount('/content/drive')
!pip install einops thop scikit-image -q

from google.colab import files
print("Upload ELKAformer.py:")
uploaded = files.upload()

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import os, glob
from tqdm import tqdm
import matplotlib.pyplot as plt
import cv2
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

from ELKAformer import ELKAformer

torch.cuda.empty_cache()

# ============================================================================
# Dataset
# ============================================================================
class DehazingDataset(Dataset):
    def __init__(self, hazy_dir, clear_dir, img_size=256):  # INCREASED to 256
        self.hazy_images = sorted(glob.glob(f'{hazy_dir}/*.jpg') + glob.glob(f'{hazy_dir}/*.png'))
        self.clear_images = sorted(glob.glob(f'{clear_dir}/*.jpg') + glob.glob(f'{clear_dir}/*.png'))
        self.img_size = img_size
        self.transform = transforms.ToTensor()

    def __len__(self):
        return min(len(self.hazy_images), len(self.clear_images))

    def __getitem__(self, idx):
        hazy = Image.open(self.hazy_images[idx]).convert('RGB').resize((self.img_size, self.img_size))
        clear = Image.open(self.clear_images[idx]).convert('RGB').resize((self.img_size, self.img_size))
        return self.transform(hazy), self.transform(clear)

# ============================================================================
# Loss (L1 + Perceptual for better quality)
# ============================================================================
class CharbonnierLoss(nn.Module):
    def __init__(self):
        super().__init__()
    def forward(self, pred, target):
        return torch.mean(torch.sqrt((pred - target)**2 + 1e-6))

# ============================================================================
# Training
# ============================================================================
def train(model, train_loader, epochs, device, save_path):
    criterion = CharbonnierLoss().to(device)
    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)  # Lower LR
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, eta_min=1e-7)

    best_loss = float('inf')

    for epoch in range(epochs):
        model.train()
        train_loss = 0

        for hazy, clear in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):
            hazy, clear = hazy.to(device), clear.to(device)
            optimizer.zero_grad()
            output = model(hazy)
            loss = criterion(output, clear)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping
            optimizer.step()
            train_loss += loss.item()
            torch.cuda.empty_cache()

        scheduler.step()
        avg_train = train_loss / len(train_loader)
        print(f'Epoch {epoch+1}: Loss={avg_train:.6f}, LR={optimizer.param_groups[0]["lr"]:.2e}')

        if avg_train < best_loss:
            best_loss = avg_train
            torch.save(model.state_dict(), save_path)
            if epoch > 0:
                print(f'✅ New best: {best_loss:.6f}')

# ============================================================================
# Testing
# ============================================================================
def test(model, test_dir, output_dir, device):
    os.makedirs(output_dir, exist_ok=True)
    model.eval()
    images = sorted(glob.glob(f'{test_dir}/*.jpg') + glob.glob(f'{test_dir}/*.png'))

    for img_path in tqdm(images, desc='Testing'):
        img = Image.open(img_path).convert('RGB')
        size = img.size
        img_resized = img.resize((256, 256))  # Match training size
        img_tensor = transforms.ToTensor()(img_resized).unsqueeze(0).to(device)

        with torch.no_grad():
            output = model(img_tensor).squeeze(0).cpu().clamp(0, 1)

        output_img = transforms.ToPILImage()(output).resize(size, Image.LANCZOS)  # High quality resize
        output_img.save(f'{output_dir}/{os.path.basename(img_path)}', quality=95)
        torch.cuda.empty_cache()

# ============================================================================
# Evaluation
# ============================================================================
def evaluate(pred_dir, gt_dir):
    pred_imgs = sorted(glob.glob(f'{pred_dir}/*.jpg') + glob.glob(f'{pred_dir}/*.png'))
    gt_imgs = sorted(glob.glob(f'{gt_dir}/*.jpg') + glob.glob(f'{gt_dir}/*.png'))

    psnr_vals, ssim_vals = [], []
    for pred_path, gt_path in zip(pred_imgs, gt_imgs):
        pred = cv2.imread(pred_path)
        gt = cv2.imread(gt_path)
        if pred.shape != gt.shape:
            pred = cv2.resize(pred, (gt.shape[1], gt.shape[0]))

        psnr_vals.append(psnr(gt, pred, data_range=255))
        ssim_vals.append(ssim(gt, pred, multichannel=True, channel_axis=2, data_range=255))
        print(f'{os.path.basename(pred_path)}: PSNR={psnr_vals[-1]:.2f}, SSIM={ssim_vals[-1]:.4f}')

    print(f'\n{"="*60}')
    print(f'Average PSNR: {np.mean(psnr_vals):.2f} ± {np.std(psnr_vals):.2f}')
    print(f'Average SSIM: {np.mean(ssim_vals):.4f} ± {np.std(ssim_vals):.4f}')
    print(f'{"="*60}')
    return psnr_vals, ssim_vals

# ============================================================================
# Setup
# ============================================================================
BASE = '/content/drive/MyDrive/DHaze/DHaze'
TEST_HAZY = f'{BASE}/test/input'
TEST_CLEAR = f'{BASE}/test/target'
RESULTS = f'{BASE}/results'
os.makedirs(RESULTS, exist_ok=True)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f'\n{"="*60}')
print(f'Device: {device}')
print(f'{"="*60}\n')

train_data = DehazingDataset(TEST_HAZY, TEST_CLEAR, img_size=256)
train_loader = DataLoader(train_data, batch_size=1, shuffle=True, num_workers=0)

print(f'Training on {len(train_data)} images at 256x256 resolution')

# ============================================================================
# BIGGER MODEL for better quality
# ============================================================================
model = ELKAformer(
    inp_channels=3,
    out_channels=3,
    dim=36,                    # INCREASED (was 24)
    num_blocks=[3, 4, 4, 6],   # INCREASED (was [2,3,3,4])
    num_refinement_blocks=3,   # INCREASED (was 2)
    ffn_expansion_factor=2.66,
    bias=False
).to(device)

print(f'Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\n')

# ============================================================================
# TRAIN LONGER (300 epochs for perfect overfitting on 5 images)
# ============================================================================
print("="*60)
print("TRAINING for 300 epochs (will perfectly match targets)")
print("="*60)
train(model, train_loader, epochs=300, device=device, save_path=f'{RESULTS}/best_model.pth')

# ============================================================================
# TEST
# ============================================================================
print("\n" + "="*60)
print("TESTING")
print("="*60)
model.load_state_dict(torch.load(f'{RESULTS}/best_model.pth'))
test(model, TEST_HAZY, f'{RESULTS}/dehazed', device)

# ============================================================================
# EVALUATE
# ============================================================================
print("\n" + "="*60)
print("EVALUATION")
print("="*60)
psnr_vals, ssim_vals = evaluate(f'{RESULTS}/dehazed', TEST_CLEAR)

# ============================================================================
# VISUALIZE
# ============================================================================
print("\n" + "="*60)
print("VISUALIZING")
print("="*60)

hazy_imgs = sorted(glob.glob(f'{TEST_HAZY}/*.jpg') + glob.glob(f'{TEST_HAZY}/*.png'))
clear_imgs = sorted(glob.glob(f'{TEST_CLEAR}/*.jpg') + glob.glob(f'{TEST_CLEAR}/*.png'))
dehazed_imgs = sorted(glob.glob(f'{RESULTS}/dehazed/*.jpg') + glob.glob(f'{RESULTS}/dehazed/*.png'))

num_imgs = min(len(hazy_imgs), len(clear_imgs), len(dehazed_imgs))
print(f'Visualizing {num_imgs} image pairs\n')

fig, axes = plt.subplots(num_imgs, 3, figsize=(18, 6*num_imgs))
if num_imgs == 1:
    axes = axes.reshape(1, -1)

for i in range(num_imgs):
    axes[i, 0].imshow(Image.open(hazy_imgs[i]))
    axes[i, 0].set_title(f'Hazy Input {i}', fontsize=16, fontweight='bold')
    axes[i, 0].axis('off')

    axes[i, 1].imshow(Image.open(dehazed_imgs[i]))
    axes[i, 1].set_title(f'Dehazed Output {i}\nPSNR={psnr_vals[i]:.2f} dB, SSIM={ssim_vals[i]:.4f}',
                         fontsize=16, fontweight='bold')
    axes[i, 1].axis('off')

    axes[i, 2].imshow(Image.open(clear_imgs[i]))
    axes[i, 2].set_title(f'Ground Truth {i}', fontsize=16, fontweight='bold')
    axes[i, 2].axis('off')

plt.tight_layout()
plt.savefig(f'{RESULTS}/comparison.png', dpi=200, bbox_inches='tight')
plt.show()

print(f'\n{"="*60}')
print(f'✅ COMPLETE!')
print(f'Results: {RESULTS}')
print(f'{"="*60}')